{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "50a5a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21519e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape \n",
    "the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0e4e330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/Users/mitssverma/Selenium/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "91c3f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c2fa95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "68de196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "866958aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ceed5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"title fw500 ellipsis\"]'):\n",
    "    title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "765922dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class = \"fleft grey-text br2 placeHolderLi location\"]'):\n",
    "    location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4bd69301",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"subTitle ellipsis fleft\"]'):\n",
    "    company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "64606787",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = []\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class = \"fleft grey-text br2 placeHolderLi experience\"]'):\n",
    "    exp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cff84bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analysis Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job opportunity For Data Analyst at Trellance ...</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>CURise Analytics Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0                           Sr.Business Data Analyst   \n",
       "1                                    Sr Data Analyst   \n",
       "2                       Senior Data Analysis Analyst   \n",
       "3  Job opportunity For Data Analyst at Trellance ...   \n",
       "4                                       Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6            Master Data Management Business Analyst   \n",
       "7                            Hiring For Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                             Associate Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, karnataka\\n(WFH during Co...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "3                     Bangalore/Bengaluru, Ahmedabad   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5               Bangalore/Bengaluru(Old Madras Road)   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                 Company Name Experience  \n",
       "0                   Collabera   6-11 Yrs  \n",
       "1             Thomson Reuters    5-8 Yrs  \n",
       "2                       Capco   7-12 Yrs  \n",
       "3  CURise Analytics Pvt. Ltd.    0-2 Yrs  \n",
       "4             Thomson Reuters    2-3 Yrs  \n",
       "5                    KrazyBee    3-6 Yrs  \n",
       "6                   Accenture    6-8 Yrs  \n",
       "7                    Flipkart    2-5 Yrs  \n",
       "8                       Wipro    4-9 Yrs  \n",
       "9                       Optum    2-7 Yrs  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nauk = pd.DataFrame({'Job-title':title, 'Location':location, 'Company Name':company, 'Experience':exp})\n",
    "nauk[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1d607f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div/a')\n",
    "home.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "41158141",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "217ae4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cfc37ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "00d6ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"title fw500 ellipsis\"]'):\n",
    "    title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ec9b0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class = \"fleft grey-text br2 placeHolderLi location\"]'):\n",
    "    location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "59419d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"subTitle ellipsis fleft\"]'):\n",
    "    company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "efd38a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Principal - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                   Hiring For Senior Data Scientist   \n",
       "2                                 Dataiku Consultant   \n",
       "3                                     Data Scientist   \n",
       "4  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "5                 Data Scientist: Advanced Analytics   \n",
       "6                                 Research Scientist   \n",
       "7                         Principal - Data Scientist   \n",
       "8            Research and Development -AI/ML -(PhD )   \n",
       "9  Opportunity For Data Scientist - Female Candid...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "1                          Bangalore/Bengaluru, Pune   \n",
       "2                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "9  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "\n",
       "                      Company Name  \n",
       "0                            Wipro  \n",
       "1  TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                            Wipro  \n",
       "3                Applied Materials  \n",
       "4                              PwC  \n",
       "5                              IBM  \n",
       "6                              IBM  \n",
       "7               Schneider Electric  \n",
       "8                              EXL  \n",
       "9                             PayU  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nau = pd.DataFrame({'Job-title':title, 'Location':location, 'Company Name':company})\n",
    "nau[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d4633004",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/Users/mitssverma/Selenium/chromedriver')\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "20988655",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "button = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search.send_keys('Data Scientist')  \n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d8b526cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/i')\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "781e1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0e767ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"title fw500 ellipsis\"]'):\n",
    "    title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2f32ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class = \"fleft grey-text br2 placeHolderLi location\"]'):\n",
    "    location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "16adb6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"subTitle ellipsis fleft\"]'):\n",
    "    company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d2dca470",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = []\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class = \"fleft grey-text br2 placeHolderLi experience\"]'):\n",
    "    exp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ac08e1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "      <td>Teq Analytics</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job-title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1             Senior Associate - Data Science   \n",
       "2            Data Scientist - Noida/Bangalore   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5        Data Scientist - Machine learning AI   \n",
       "6              Data Scientist - MIND Infotech   \n",
       "7           Data Scientist - Engine Algorithm   \n",
       "8                    Knowledge/Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...   \n",
       "6                                              Noida   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                        Delhi / NCR   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                               Company Name Experience  \n",
       "0                   Boston Consulting Group    2-5 Yrs  \n",
       "1                              Black Turtle    4-7 Yrs  \n",
       "2                                       EXL   5-10 Yrs  \n",
       "3                 8KMiles Software Services    2-7 Yrs  \n",
       "4                 8KMiles Software Services    2-7 Yrs  \n",
       "5                             Teq Analytics    3-8 Yrs  \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs  \n",
       "7                              Primo Hiring    1-3 Yrs  \n",
       "8                   BOLD Technology Systems    3-6 Yrs  \n",
       "9   Mount Talent Consulting Private Limited    2-4 Yrs  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nauk = pd.DataFrame({'Job-title':title, 'Location':location, 'Company Name':company, 'Experience':exp})\n",
    "nauk[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: 1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2c630a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = webdriver.Chrome(r'/Users/mitssverma/Selenium/chromedriver')\n",
    "flip.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f5ebc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "close = flip.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b9956b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = flip.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search.send_keys('sunglasses')\n",
    "search.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "956f0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "for i in flip.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "    brand.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e544f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "descrp = []\n",
    "for i in flip.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "    descrp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b531b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = []\n",
    "for i in flip.find_elements(By.CLASS_NAME,'_30jeq3'):\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "74587052",
   "metadata": {},
   "outputs": [],
   "source": [
    "off = []\n",
    "for i in flip.find_elements(By.CLASS_NAME,'_3Ay6Sb'):\n",
    "    off.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a81f7fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 45, 45)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand),len(descrp),len(price),len(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bd8cd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "nex = flip.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "nex.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "db5b0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "    brand.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0d5e0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "    descrp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "96ef4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.CLASS_NAME,'_30jeq3'):\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8e26f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.CLASS_NAME,'_3Ay6Sb'):\n",
    "    off.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1954e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 90, 90)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand),len(descrp),len(price),len(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b8843be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = flip.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "ne.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e7f3eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "    brand.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "99e1b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "    descrp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2d8dca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.CLASS_NAME,'_30jeq3'):\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "22d353e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in flip.find_elements(By.CLASS_NAME,'_3Ay6Sb'):\n",
    "    off.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "13f3b8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 135, 135)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand),len(descrp),len(price),len(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "998da042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Decription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹177</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹315</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Retro Squar...</td>\n",
       "      <td>₹259</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹809</td>\n",
       "      <td>10% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>JustChhapo</td>\n",
       "      <td>Polarized Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Riding Glasses Aviator Sunglass...</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Night Vision, UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹245</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Sports Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                         Decription Price  \\\n",
       "0         DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...  ₹177   \n",
       "1        New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹264   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)  ₹315   \n",
       "4           SUNBEE  UV Protection, Polarized, Mirrored Retro Squar...  ₹259   \n",
       "..             ...                                                ...   ...   \n",
       "95  kingsunglasses   Mirrored, UV Protection Wayfarer Sunglasses (53)  ₹809   \n",
       "96      JustChhapo      Polarized Retro Square Sunglasses (Free Size)  ₹664   \n",
       "97          GANSTA  UV Protection, Riding Glasses Aviator Sunglass...  ₹664   \n",
       "98            SRPM  Night Vision, UV Protection Round Sunglasses (54)  ₹245   \n",
       "99        Fastrack        UV Protection Sports Sunglasses (Free Size)  ₹639   \n",
       "\n",
       "      Offer  \n",
       "0   82% off  \n",
       "1   89% off  \n",
       "2   20% off  \n",
       "3   87% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  10% off  \n",
       "96  66% off  \n",
       "97  66% off  \n",
       "98  75% off  \n",
       "99  20% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipkart = pd.DataFrame({'Brand Name':brand[0:100], \"Decription\":descrp[0:100], 'Price':price[0:100], 'Offer':off[0:100]})\n",
    "flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d070ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e6fc68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = flip.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[1]/div/a[1]/img')\n",
    "home.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "65d2e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = flip.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search.send_keys('iphone 11')\n",
    "search.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8e668ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone = flip.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[1]/div[1]/div/div/img')\n",
    "iphone.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a2c76588",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = flip.window_handles[1]\n",
    "flip.switch_to.window(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7b349d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_re = flip.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/a/div/span')\n",
    "all_re.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8c7d29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "star = []\n",
    "comm = []\n",
    "bri = []\n",
    "for page in range(0,10):\n",
    "    for i in flip.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "        star.append(i.text)\n",
    "        \n",
    "    for i in flip.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]'):\n",
    "        comm.append(i.text)\n",
    "    \n",
    "    for i in flip.find_elements(By.XPATH,'//div[@class = \"t-ZTKy\"]'):\n",
    "        bri.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4641a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Star</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Brief</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Star             Comments  \\\n",
       "0     5       Simply awesome   \n",
       "1     5     Perfect product!   \n",
       "2     5  Best in the market!   \n",
       "3     5   Highly recommended   \n",
       "4     5    Worth every penny   \n",
       "..  ...                  ...   \n",
       "95    5            Fabulous!   \n",
       "96    5        Great product   \n",
       "97    5    Worth every penny   \n",
       "98    4          Good choice   \n",
       "99    5   Highly recommended   \n",
       "\n",
       "                                                Brief  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  So far it’s been an AMAZING experience coming ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone = pd.DataFrame({'Star':star, 'Comments':comm, 'Brief':bri})\n",
    "phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "86b25511",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "15ef4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = flip.window_handles[0]\n",
    "flip.switch_to.window(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c0d760bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = flip.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[1]/div/a[1]/img')\n",
    "home.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0664b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = flip.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search.send_keys('sneakers')\n",
    "search.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b103c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,des,pir,off = [],[],[],[]\n",
    "for page in range(0,3):\n",
    "    for i in flip.find_elements(By.CLASS_NAME,'_2WkVRV'):\n",
    "        name.append(i.text)\n",
    "    \n",
    "    for i in flip.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "        des.append(i.text)\n",
    "        \n",
    "    for i in flip.find_elements(By.XPATH,'//div[@class = \"_30jeq3\"]'):\n",
    "        pir.append(i.text)\n",
    "    \n",
    "    for i in flip.find_elements(By.CLASS_NAME,'_3Ay6Sb'):\n",
    "        off.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f64b1632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 120, 135)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name),len(des),len(pir),len(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d78bfd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price and Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZF - ALFIYA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449 and 55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEWEYU</td>\n",
       "      <td>Fashionable casual sneaker shoes Sneakers For ...</td>\n",
       "      <td>₹499 and 75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOODLAND</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,096 and 30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹284 and 78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹299 and 76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>ultra light Comfertable Slip-On and lace-ups c...</td>\n",
       "      <td>₹625 and 50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹397 and 78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹649 and 85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹1,763 and 55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Scull Wings</td>\n",
       "      <td>White &amp; Black Sneakers For Men Casual Shoes Fo...</td>\n",
       "      <td>₹496 and 62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                Product Description  \\\n",
       "0   ZF - ALFIYA                                   Sneakers For Men   \n",
       "1        FEWEYU  Fashionable casual sneaker shoes Sneakers For ...   \n",
       "2      WOODLAND                                   Sneakers For Men   \n",
       "3        BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "4        BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "..          ...                                                ...   \n",
       "95     CALCADOS  ultra light Comfertable Slip-On and lace-ups c...   \n",
       "96     KWIK FIT  Kwik FIT casual sneaker shoes and partywear sh...   \n",
       "97       Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "98         PUMA                   Puma Smash v2 L Sneakers For Men   \n",
       "99  Scull Wings  White & Black Sneakers For Men Casual Shoes Fo...   \n",
       "\n",
       "       Price and Offer  \n",
       "0     ₹449 and 55% off  \n",
       "1     ₹499 and 75% off  \n",
       "2   ₹2,096 and 30% off  \n",
       "3     ₹284 and 78% off  \n",
       "4     ₹299 and 76% off  \n",
       "..                 ...  \n",
       "95    ₹625 and 50% off  \n",
       "96    ₹397 and 78% off  \n",
       "97    ₹649 and 85% off  \n",
       "98  ₹1,763 and 55% off  \n",
       "99    ₹496 and 62% off  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneaker = pd.DataFrame({'Brand':name[0:100], 'Product Description':des[0:100], 'Price':pir[0:100], 'Offer':off[0:100]})\n",
    "sneaker['Price and Offer'] = sneaker['Price'] +' and ' + sneaker['Offer']\n",
    "sneaker.drop(columns = ['Price','Offer'],inplace=True)\n",
    "sneaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop: 1. Title\n",
    "2. Ratings 3. Price'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ec15a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/Users/mitssverma/Selenium/chromedriver')\n",
    "driver.get('https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "478983e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('laptop')\n",
    "search.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "bdd887be",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[2]/li[13]/span/a/div/label/i')\n",
    "core.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cf3190d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class = \"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]'):\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "21b6ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = []\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class = \"a-price-whole\"]'):\n",
    "    rate.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f4725e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = []\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-size-base s-underline-text\"]'):\n",
    "    ss.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "022ac6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 22)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rate),len(name),len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "26b87534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...</td>\n",
       "      <td>75,990</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>73,990</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...</td>\n",
       "      <td>87,900</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>86,990</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,990</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LG Gram 16 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>85,499</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>82,990</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Envy 11th Gen Intel Evo Core i7 14 inch(35....</td>\n",
       "      <td>99,400</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>57,890</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop Name   Price Rating\n",
       "0  Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...  75,990      9\n",
       "1  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...  73,990     21\n",
       "2  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  89,990     26\n",
       "3  Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...  87,900      5\n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  86,990     50\n",
       "5  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  79,990     16\n",
       "6  LG Gram 16 Intel Evo 11th Gen i7 Thin & Light ...  85,499    143\n",
       "7  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  82,990     14\n",
       "8  HP Envy 11th Gen Intel Evo Core i7 14 inch(35....  99,400      7\n",
       "9  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  57,890    161"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap = pd.DataFrame({'Laptop Name': name[0:10], 'Price': rate[0:10], 'Rating' : ss[0:10]})\n",
    "lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e9144ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1 = webdriver.Chrome(r'/Users/mitssverma/Selenium/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00e3d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1.get('https://www.ambitionbox.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "442a69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = driver1.find_element(By.XPATH,'//a[@class = \"link jobs\"]')\n",
    "driver1.get(job.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20113e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver1.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "886bea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = driver1.find_element(By.XPATH,'//span[@class = \"ctas-btn-medium\"]')\n",
    "se.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a6cedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = driver1.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i')\n",
    "lo.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c08190c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selo = driver1.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "selo.send_keys('noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d402be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = driver1.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "no.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52f0f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "company,time,rating = [],[],[]\n",
    "for i in driver1.find_elements(By.XPATH,'//a[@class = \"title noclick\"]'):\n",
    "    company.append(i.text)\n",
    "    \n",
    "for i in driver1.find_elements(By.XPATH,'//span[@class = \"body-small-l\"]'):\n",
    "    time.append(i.text)\n",
    "    \n",
    "for i in driver1.find_elements(By.XPATH,'//span[@class = \"body-small\"]'):\n",
    "    rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b1500dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 20)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company),len(rating),len(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45dcdbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist- Forecasting and R or Python</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning Algorithms (...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/Big Data (0-...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Info Edge - Data Scientist - Machine Learning/...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Info Edge - Senior Data Scientist - Machine Le...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LatentBridge - Data Scientist - Python/R (2-6 ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Trainer | AI | Machine Learning |...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal Scientist - Machine Learning - IT (1...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>28d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - NLP</td>\n",
       "      <td>3.8</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Rating     Time\n",
       "0                              Senior Data Scientist    4.1   8d ago\n",
       "1        Data Scientist- Forecasting and R or Python    4.0  15d ago\n",
       "2  Data Scientist - Machine Learning Algorithms (...    4.3   6d ago\n",
       "3  Data Scientist - Machine Learning/Big Data (0-...    3.9  13d ago\n",
       "4  Info Edge - Data Scientist - Machine Learning/...    3.9  14d ago\n",
       "5  Info Edge - Senior Data Scientist - Machine Le...    3.9  14d ago\n",
       "6  LatentBridge - Data Scientist - Python/R (2-6 ...    4.5  14d ago\n",
       "7  Data Science Trainer | AI | Machine Learning |...    3.8   1d ago\n",
       "8  Principal Scientist - Machine Learning - IT (1...    3.9  28d ago\n",
       "9                               Data Scientist - NLP    3.8  14d ago"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amiti = pd.DataFrame({'Company Name': company, 'Rating': rating, 'Time': time[0::2]})\n",
    "amiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "399ebe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = driver1.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/div/div[1]/div/div[3]/a')\n",
    "sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0780a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_sal = driver1.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "sea_sal.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "be0b2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = driver1.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "da.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0299963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,exp = [],[]\n",
    "for i in driver1.find_elements(By.XPATH,'//div[@class = \"company-info\"]')[:10]:\n",
    "    name.append(i.text.split('\\n')[0])\n",
    "    exp.append(i.text.split('\\n')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3feadb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal,avg = [],[]\n",
    "for i in driver1.find_elements(By.XPATH,'//div[@class = \"value body-medium\"]'):\n",
    "    sal.append(i.text)\n",
    "minimum = sal[::2]\n",
    "maximum = sal[1::2]\n",
    "\n",
    "for i in driver1.find_elements(By.XPATH,'//p[@class = \"averageCtc\"]'):\n",
    "    avg.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5c490f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>3 yrs experience (based on 12 salaries)</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 30.6L</td>\n",
       "      <td>₹ 36.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>3-4 yrs experience (based on 33 salaries)</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 20.8L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2 yrs experience (based on 15 salaries)</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 16.7L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3-4 yrs experience (based on 32 salaries)</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 22.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>3-4 yrs experience (based on 21 salaries)</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>2-4 yrs experience (based on 89 salaries)</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>2-4 yrs experience (based on 51 salaries)</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>2-4 yrs experience (based on 57 salaries)</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>3-4 yrs experience (based on 21 salaries)</td>\n",
       "      <td>₹ 7.6L</td>\n",
       "      <td>₹ 13.2L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>2-4 yrs experience (based on 69 salaries)</td>\n",
       "      <td>₹ 7.0L</td>\n",
       "      <td>₹ 12.8L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company Name                                 Experience  \\\n",
       "0            Walmart    3 yrs experience (based on 12 salaries)   \n",
       "1           Ab Inbev  3-4 yrs experience (based on 33 salaries)   \n",
       "2                 ZS    2 yrs experience (based on 15 salaries)   \n",
       "3              Optum  3-4 yrs experience (based on 32 salaries)   \n",
       "4       Reliance Jio  3-4 yrs experience (based on 21 salaries)   \n",
       "5  Fractal Analytics  2-4 yrs experience (based on 89 salaries)   \n",
       "6    Tiger Analytics  2-4 yrs experience (based on 51 salaries)   \n",
       "7       UnitedHealth  2-4 yrs experience (based on 57 salaries)   \n",
       "8        EXL Service  3-4 yrs experience (based on 21 salaries)   \n",
       "9           Deloitte  2-4 yrs experience (based on 69 salaries)   \n",
       "\n",
       "  Minimum Salary Average Salary Maximum Salary  \n",
       "0        ₹ 25.0L        ₹ 30.6L        ₹ 36.0L  \n",
       "1        ₹ 15.0L        ₹ 20.8L        ₹ 26.2L  \n",
       "2        ₹ 11.0L        ₹ 16.7L        ₹ 22.0L  \n",
       "3        ₹ 11.0L        ₹ 15.9L        ₹ 22.5L  \n",
       "4         ₹ 5.6L        ₹ 15.7L        ₹ 26.2L  \n",
       "5        ₹ 10.0L        ₹ 15.5L        ₹ 23.0L  \n",
       "6         ₹ 9.0L        ₹ 14.8L        ₹ 20.0L  \n",
       "7         ₹ 8.3L        ₹ 14.0L        ₹ 21.1L  \n",
       "8         ₹ 7.6L        ₹ 13.2L        ₹ 21.0L  \n",
       "9         ₹ 7.0L        ₹ 12.8L        ₹ 25.0L  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amiti_sal = pd.DataFrame({'Company Name':name, 'Experience':exp, 'Minimum Salary':minimum, 'Average Salary':avg, 'Maximum Salary':maximum})\n",
    "amiti_sal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
